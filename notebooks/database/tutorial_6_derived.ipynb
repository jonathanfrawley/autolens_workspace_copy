{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database 5: Derived\n",
    "===================\n",
    "\n",
    "This tutorial describes how to estimate derived quantities from a model-fit, where a derived quantity is one which may\n",
    "be used for the analysis and interpreation of results but is not explicitly a free parameter in the non-linear search.\n",
    "\n",
    "An example is the total luminosity of the lens or source galaxy, or total mass of the lens galaxy. These quantities\n",
    "are estimated by a PyAutoLens model-fit, but are estimated from a combination of lens model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-13T18:29:50.293698Z",
     "iopub.status.busy": "2021-04-13T18:29:50.293103Z",
     "iopub.status.idle": "2021-04-13T18:29:53.633745Z",
     "shell.execute_reply": "2021-04-13T18:29:53.634009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Jammy/Code/PyAuto/autolens_workspace\n",
      "Working Directory has been set to `/mnt/c/Users/Jammy/Code/PyAuto/autolens_workspace`\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from pyprojroot import here\n",
    "workspace_path = str(here())\n",
    "%cd $workspace_path\n",
    "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
    "\n",
    "from os import path\n",
    "import autofit as af\n",
    "import autolens as al\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set up the aggregator as we did in the previous tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-13T18:29:53.636637Z",
     "iopub.status.busy": "2021-04-13T18:29:53.636318Z",
     "iopub.status.idle": "2021-04-13T18:29:53.939208Z",
     "shell.execute_reply": "2021-04-13T18:29:53.938861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregator loading search_outputs... could take some time.\n",
      "\n",
      " A total of 6 search_outputs and results were found.\n"
     ]
    }
   ],
   "source": [
    "# from autofit.database.aggregator import Aggregator\n",
    "# database_file = path.join(\"output\", \"database\", \"database.sqlite\")\n",
    "# agg = Aggregator.from_database(path.join(database_file))\n",
    "agg = af.Aggregator(directory=path.join(\"output\", \"database\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, lets compute the axis ratio of a lens model, including the errors on the axis ratio. In the previous tutorials, \n",
    "we saw that the errors on a quantity like the elliptical_comps is simple, because it was sampled by the non-linear \n",
    "search. Thus, to get their we can uses the Samples object to simply marginalize over all over parameters via the 1D \n",
    "Probability Density Function (PDF).\n",
    "\n",
    "But what if we want the errors on the axis-ratio? This wasn`t a free parameter in our model so we can`t just \n",
    "marginalize over all other parameters.\n",
    "\n",
    "Instead, we need to compute the axis-ratio of every lens model sampled by the non-linear search and from this determine \n",
    "the PDF of the axis-ratio. When combining the different axis-ratios we weight each value by its `weight`. For Dynesty,\n",
    "the nested sampler we fitted our aggregator sample with, this down weights the model which gave lower likelihood fits.\n",
    "For other non-linear search methods (e.g. MCMC) the weights can take on a different meaning but can still be used for\n",
    "combining different model results.\n",
    "\n",
    "Below, we get an instance of every Dynesty sample using the `Samples`, compute that models axis-ratio, store them in a \n",
    "list and find the weighted median value with errors.\n",
    "\n",
    "This function takes the list of axis-ratio values with their sample weights and computes the weighted mean and \n",
    "standard deviation of these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-13T18:29:53.942276Z",
     "iopub.status.busy": "2021-04-13T18:29:53.941947Z",
     "iopub.status.idle": "2021-04-13T18:29:53.943871Z",
     "shell.execute_reply": "2021-04-13T18:29:53.943530Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def weighted_mean_and_standard_deviation(values, weights):\n",
    "    \"\"\"\n",
    "    Return the weighted average and standard deviation.\n",
    "    values, weights -- Numpy ndarrays with the same shape.\n",
    "    \"\"\"\n",
    "    values = np.asarray(values)\n",
    "    weights = np.asarray(weights)\n",
    "    average = np.average(values, weights=weights)\n",
    "    # Fast and numerically precise:\n",
    "    variance = np.average((values - average) ** 2, weights=weights)\n",
    "    return average, np.sqrt(variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we iterate over each Samples object, using every model instance to compute its axis-ratio. We combine these \n",
    "axis-ratios with the samples weights to give us the weighted mean axis-ratio and error.\n",
    "\n",
    "To do this, we again use a generator. Whislt the axis-ratio is a fairly light-weight value, and this could be\n",
    "performed using a list without crippling your comptuer`s memory, for other quantities this is not the case. Thus, for\n",
    "computing derived quantities it is good practise to always use a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-13T18:29:53.948400Z",
     "iopub.status.busy": "2021-04-13T18:29:53.948058Z",
     "iopub.status.idle": "2021-04-13T18:30:17.304753Z",
     "shell.execute_reply": "2021-04-13T18:30:17.305003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axis Ratios:\n",
      "[0.9007599933964339, 0.6034352993848718, 0.9000098900866702, 0.6012448543132954, 0.9004427843386927, 0.5982100750785653]\n",
      "Axis Ratio Errors:\n",
      "[0.0, 0.0019096257516870536, 0.0, 0.001034099617973187, 0.0, 0.0006077850716453862]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def axis_ratio_error_from_agg_obj(agg_obj):\n",
    "\n",
    "    samples = agg_obj.samples\n",
    "\n",
    "    axis_ratios = []\n",
    "    weights = []\n",
    "\n",
    "    for sample_index in range(samples.total_accepted_samples):\n",
    "\n",
    "        weight = samples.samples[sample_index].weights\n",
    "\n",
    "        if weight > 1e-4:\n",
    "\n",
    "            instance = samples.instance_from_sample_index(sample_index=sample_index)\n",
    "\n",
    "            axis_ratio = al.convert.axis_ratio_from(\n",
    "                elliptical_comps=instance.galaxies.lens.mass.elliptical_comps\n",
    "            )\n",
    "\n",
    "            axis_ratios.append(axis_ratio)\n",
    "            weights.append(weight)\n",
    "\n",
    "    return weighted_mean_and_standard_deviation(values=axis_ratios, weights=weights)\n",
    "\n",
    "\n",
    "axis_ratio_values = list(agg.map(func=axis_ratio_error_from_agg_obj))\n",
    "axis_ratios = [value[0] for value in axis_ratio_values]\n",
    "axis_ratio_errors = [value[1] for value in axis_ratio_values]\n",
    "\n",
    "print(\"Axis Ratios:\")\n",
    "print(axis_ratios)\n",
    "\n",
    "print(\"Axis Ratio Errors:\")\n",
    "print(axis_ratio_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also iterate over every Fit of our results, to extracting derived information on the fit. Below, we reperform\n",
    "every source reconstruction of the fit and ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-13T18:30:17.307567Z",
     "iopub.status.busy": "2021-04-13T18:30:17.307236Z",
     "iopub.status.idle": "2021-04-13T18:30:18.040397Z",
     "shell.execute_reply": "2021-04-13T18:30:18.039969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "fit_gen = al.agg.FitImaging(aggregator=agg)\n",
    "\n",
    "for fit in fit_gen:\n",
    "\n",
    "    print(fit.inversion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
