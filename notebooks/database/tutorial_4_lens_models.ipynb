{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Database 4: Lens Models\n",
        "=======================\n",
        "\n",
        "This tutorial builds on the tutorial `a1_samples`, where we use the aggregator to load models from a non-linear\n",
        "search and visualize and interpret results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "from astropy import cosmology as cosmo\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt\n",
        "import matplotlib.pyplot as plt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, set up the aggregator as we did in the previous tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agg = af.Aggregator.from_database(\"database.sqlite\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, lets create a list of instances of the maximum log likelihood models of each fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ml_instances = [samps.max_log_likelihood_instance for samps in agg.values(\"samples\")]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A model instance contains a list of `Galaxy` instances, which is what we are using to passing to functions in \n",
        "PyAutoLens. Lets create the maximum log likelihood tracer of every fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ml_tracers = [\n",
        "    al.Tracer.from_galaxies(galaxies=instance.galaxies) for instance in ml_instances\n",
        "]\n",
        "\n",
        "print(\"Maximum Log Likelihood Tracers: \\n\")\n",
        "print(ml_tracers, \"\\n\")\n",
        "print(\"Total Tracers = \", len(ml_tracers))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now lets plot their convergences, using a grid of 100 x 100 pixels (noting that this isn't` necessarily the grid used\n",
        "to fit the data in the search itself)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(shape_native=(100, 100), pixel_scales=0.1)\n",
        "\n",
        "for tracer in ml_tracers:\n",
        "    tracer_plotter = aplt.TracerPlotter(tracer=tracer, grid=grid)\n",
        "    tracer_plotter.figures_2d(convergence=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Okay, so we can make a list of tracers and plot their convergences. However, we'll run into the same problem using \n",
        "lists which we discussed in the previous tutorial. If we had fitted hundreds of images we`d have hundreds of tracers, \n",
        "overloading the memory on our laptop.\n",
        "\n",
        "We can again avoid using lists for any objects that could potentially be memory intensive, using generators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "def make_tracer_generator(agg_obj):\n",
        "\n",
        "    samples = agg_obj.samples\n",
        "\n",
        "    return al.Tracer.from_galaxies(\n",
        "        galaxies=samples.max_log_likelihood_instance.galaxies\n",
        "    )\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We `map` the function above using our aggregator to create a tracer generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer_gen = agg.map(func=make_tracer_generator)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now iterate over our tracer generator to make the plots we desire."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(shape_native=(100, 100), pixel_scales=0.1)\n",
        "\n",
        "for tracer in tracer_gen:\n",
        "\n",
        "    tracer_plotter = aplt.TracerPlotter(tracer=tracer, grid=grid)\n",
        "    tracer_plotter.figures_2d(convergence=True, potential=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Its cumbersome to always have to define a `make_tracer_generator` function to make a tracer generator, given that \n",
        "you`ll probably do the exact same thing in every Jupyter Notebook you ever write!\n",
        "\n",
        "PyAutoLens`s aggregator module (imported as `agg`) has convenience methods to save you time and make your notebooks\n",
        "cleaner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer_gen = al.agg.Tracer(aggregator=agg)\n",
        "\n",
        "for tracer in tracer_gen:\n",
        "\n",
        "    tracer_plotter = aplt.TracerPlotter(tracer=tracer, grid=grid)\n",
        "    tracer_plotter.figures_2d(convergence=True, potential=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because instances are just lists of galaxies we can directly extract attributes of the `Galaxy` class. Lets print \n",
        "the Einstein mass of each of our most-likely lens galaxies.\n",
        "\n",
        "The model instance uses the model defined by a pipeline. In this pipeline, we called the lens galaxy `lens`.\n",
        "\n",
        "For illustration, lets do this with a list first:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Maximum Log Likelihood Lens Einstein Masses:\")\n",
        "\n",
        "for instance in ml_instances:\n",
        "\n",
        "    einstein_mass = instance.galaxies.lens.einstein_mass_angular_from_grid(grid=grid)\n",
        "\n",
        "    print(\"Einstein Mass (angular units) = \", einstein_mass)\n",
        "\n",
        "    critical_surface_density = al.util.cosmology.critical_surface_density_between_redshifts_from(\n",
        "        redshift_0=instance.galaxies.lens.redshift,\n",
        "        redshift_1=instance.galaxies.source.redshift,\n",
        "        cosmology=cosmo.Planck15,\n",
        "    )\n",
        "\n",
        "    einstein_mass_kpc = einstein_mass * critical_surface_density\n",
        "\n",
        "    print(\"Einstein Mass (kpc) = \", einstein_mass_kpc)\n",
        "    print(\"Einstein Mass (kpc) = \", \"{:.4e}\".format(einstein_mass_kpc))\n",
        "\n",
        "    print(einstein_mass)\n",
        "\n",
        "print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now lets use a generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "def print_max_log_likelihood_mass(agg_obj):\n",
        "\n",
        "    samples = agg_obj.samples\n",
        "\n",
        "    einstein_mass = samples.instance.galaxies.lens.einstein_mass_angular_from_grid(\n",
        "        grid=grid\n",
        "    )\n",
        "\n",
        "    print(\"Einstein Mass (angular units) = \", einstein_mass)\n",
        "\n",
        "    critical_surface_density = al.util.cosmology.critical_surface_density_between_redshifts_from(\n",
        "        redshift_0=samples.instance.galaxies.lens.redshift,\n",
        "        redshift_1=samples.instance.galaxies.source.redshift,\n",
        "        cosmology=cosmo.Planck15,\n",
        "    )\n",
        "\n",
        "    einstein_mass_kpc = einstein_mass * critical_surface_density\n",
        "\n",
        "    print(\"Einstein Mass (kpc) = \", einstein_mass_kpc)\n",
        "    print(\"Einstein Mass (kpc) = \", \"{:.4e}\".format(einstein_mass_kpc))\n",
        "\n",
        "\n",
        "print(\"Maximum Log Likelihood Lens Einstein Masses:\")\n",
        "agg.map(func=print_max_log_likelihood_mass)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets next do something a bit more ambitious. Lets create a plot of the einstein_radius vs axis_ratio of each \n",
        "`EllIsothermal` `MassProfile`.\n",
        "\n",
        "These plots don't use anything too memory intensive (like a tracer) so we are fine to go back to lists for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mp_instances = [samps.median_pdf_instance for samps in agg.values(\"samples\")]\n",
        "mp_einstein_radii = [\n",
        "    instance.galaxies.lens.mass.einstein_radius for instance in mp_instances\n",
        "]\n",
        "mp_elliptical_comps = [\n",
        "    instance.galaxies.lens.mass.elliptical_comps for instance in mp_instances\n",
        "]\n",
        "\n",
        "mp_axis_ratios = [\n",
        "    al.convert.axis_ratio_from(elliptical_comps=ell) for ell in mp_elliptical_comps\n",
        "]\n",
        "\n",
        "print(mp_einstein_radii)\n",
        "print(mp_axis_ratios)\n",
        "\n",
        "plt.scatter(mp_einstein_radii, mp_axis_ratios, marker=\"x\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now lets also include error bars at 3 sigma confidence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ue3_instances = [\n",
        "    samps.error_instance_at_upper_sigma(sigma=3.0) for samps in agg.values(\"samples\")\n",
        "]\n",
        "le3_instances = [\n",
        "    samps.error_instance_at_lower_sigma(sigma=3.0) for samps in agg.values(\"samples\")\n",
        "]\n",
        "\n",
        "ue3_einstein_radii = [\n",
        "    instance.galaxies.lens.mass.einstein_radius for instance in ue3_instances\n",
        "]\n",
        "le3_einstein_radii = [\n",
        "    instance.galaxies.lens.mass.einstein_radius for instance in le3_instances\n",
        "]\n",
        "ue3_elliptical_comps = [\n",
        "    instance.galaxies.lens.mass.elliptical_comps for instance in ue3_instances\n",
        "]\n",
        "le3_elliptical_comps = [\n",
        "    instance.galaxies.lens.mass.elliptical_comps for instance in le3_instances\n",
        "]\n",
        "\n",
        "ue3_axis_ratios = [\n",
        "    al.convert.axis_ratio_from(elliptical_comps=ell) for ell in ue3_elliptical_comps\n",
        "]\n",
        "le3_axis_ratios = [\n",
        "    al.convert.axis_ratio_from(elliptical_comps=ell) for ell in le3_elliptical_comps\n",
        "]\n",
        "\n",
        "plt.errorbar(\n",
        "    x=mp_einstein_radii,\n",
        "    y=mp_axis_ratios,\n",
        "    marker=\".\",\n",
        "    linestyle=\"\",\n",
        "    xerr=[le3_einstein_radii, ue3_einstein_radii],\n",
        "    yerr=[le3_axis_ratios, ue3_axis_ratios],\n",
        ")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the runner, we used the pickle_files input to search.run() to pass a .pickle file from the dataset folder to \n",
        "the database. \n",
        "\n",
        "Our strong lens dataset was created via a simulator script, so we passed the `Tracer` used to simulate the strong\n",
        "lens, which was written as a .pickle file called `true_tracer.pickle` to the search to make it accessible in the \n",
        "database. This will allow us to directly compare the inferred lens model to the `truth`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# true_tracers = [true_tracer for true_tracer in agg.values(\"true_tracer\")]\n",
        "\n",
        "print(\"Parameters used to simulate the lens dataset:\")\n",
        "# print(true_tracers)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}