{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 6: Results\n",
        "===================\n",
        "\n",
        "In the previous tutorials, each search returned a `Result` object, which we used to plot the maximum log likelihood\n",
        "fit each model-fit. In this tutorial, we'll take a look at the result object in a little more detail."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autolens as al\n",
        "import autolens.plot as aplt\n",
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Initial Setup__\n",
        "\n",
        "Lets use the model-fit performed in tutorial 1 to get a `Result` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"mass_sis__source_sersic\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", \"no_lens_light\", dataset_name)\n",
        "\n",
        "imaging = al.Imaging.from_fits(\n",
        "    image_path=path.join(dataset_path, \"image.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=imaging.shape_native, pixel_scales=imaging.pixel_scales, radius=3.0\n",
        ")\n",
        "\n",
        "imaging = imaging.apply_mask(mask=mask)\n",
        "\n",
        "model = af.Collection(\n",
        "    galaxies=af.Collection(\n",
        "        lens=af.Model(al.Galaxy, redshift=0.5, mass=al.mp.SphIsothermal),\n",
        "        source=af.Model(al.Galaxy, redshift=1.0, bulge=al.lp.SphExponential),\n",
        "    )\n",
        ")\n",
        "\n",
        "search = af.DynestyStatic(\n",
        "    path_prefix=path.join(\"howtolens\", \"chapter_2\"),\n",
        "    name=\"tutorial_1_non_linear_search\",\n",
        "    unique_tag=dataset_name,\n",
        "    nlive=40,\n",
        ")\n",
        "\n",
        "analysis = al.AnalysisImaging(dataset=imaging)\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Tracer & Fit__\n",
        "\n",
        "In the previous tutorials, we saw that this result contains the maximum log likelihood tracer and fit, which provide\n",
        "a fast way to visualize the result.\n",
        "\n",
        "(Uncomment the line below to plot the tracer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer_plotter = aplt.TracerPlotter(\n",
        "    tracer=result.max_log_likelihood_tracer, grid=mask.unmasked_grid_sub_1\n",
        ")\n",
        "tracer_plotter.subplot_tracer()\n",
        "\n",
        "fit_imaging_plotter = aplt.FitImagingPlotter(fit=result.max_log_likelihood_fit)\n",
        "fit_imaging_plotter.subplot_fit_imaging()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Samples__\n",
        "\n",
        "The result contains a lot more information about the model-fit. For example, its `Samples` object contains the complete\n",
        "set of non-linear search samples, including the parameters of every successful lens model evaluation and their log \n",
        "likelihood values. These are used for computing information about the model-fit, such as the most probably parameter\n",
        "estimates and the error inferred for every parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.samples)\n",
        "print(\"Parameters of 100th Sample:\")\n",
        "print(result.samples.parameters[99][:])\n",
        "print(\"Log Likelihood of 100th Sample:\")\n",
        "print(result.samples.log_likelihoods[99])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Workspace__\n",
        "\n",
        "We are not going into any more detail on the result variable in this tutorial, or in the **HowToLens**  lectures.\n",
        "\n",
        "A comprehensive description of the results can be found at the following script:\n",
        "\n",
        " `autolens_workspace/notebooks/imaging/modeling/result.py`\n",
        "\n",
        "\n",
        "__Database__\n",
        "\n",
        "Once a search has completed running, we have a set of results on our hard disk which we can manually inspect and \n",
        "analyse. Alternatively, we can return the results from the search.fit() method and manipulate them in a Python script.  \n",
        "\n",
        "However, imagine you have a large dataset consisting of many images of strong lenses. You analyse each image \n",
        "individually using a search, producing a large library of results on your hard disk. There will be lots of paths and \n",
        "directories to navigate, and at some point there will simply be too many results for it to be an efficient use of your \n",
        "time to analyse the results by sifting through the outputs on your hard disk one-by-one.\n",
        "\n",
        "**PyAutoLens**'s database tools solve this problem, by making it possible for us to write the results to a .sqlite \n",
        "database file and load the results from hard-disk to a Python script or Jupyter notebook. This database supports\n",
        "advanced queries, so specific results can be loaded and inspected.\n",
        "\n",
        "We won't go into any more detail on the database in this tutorial. If you think the database will be useful, checkout \n",
        "the full set of database tutorials which can be found in the folder `autolens_workspace/notebooks/database`. \n",
        "\n",
        "Here, you'll learn how to:\n",
        "\n",
        " - Use the database to query for results which fit a certain lens model or give a certan result. \n",
        " \n",
        " - Use the `Samples` to produce many different results from the fit, including error estimates on parameters and \n",
        " plots of the probability density function of parameters in 1D and 2D.\n",
        " \n",
        " - Visualize results, for example the fit to a lens dataset.\n",
        "\n",
        "\n",
        "__Wrap Up__\n",
        "\n",
        "Even if you are only modeling a small sample of lenses, if you anticipate using **PyAutoLens** for the long-term I \n",
        "strongly recommend you begin using the database to inspect and analyse your result. \n",
        "\n",
        "This is because it makes it simple to perform all analyse in a Jupyter notebook, which is the most flexible and \n",
        "versatile way to check results and make figures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}