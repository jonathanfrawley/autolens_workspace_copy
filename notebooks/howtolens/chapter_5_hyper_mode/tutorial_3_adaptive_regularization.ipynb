{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 3: Adaptive Regularization\n",
        "===================================\n",
        "\n",
        "In tutorial 1, we considered why our `Constant` `Regularization` scheme was sub-optimal. Diffferent regions of the\n",
        "source demand different levels of `Regularization`, motivating a `Regularization` scheme which adapts to the reconstructed\n",
        "source's surface brightness.\n",
        "\n",
        "This raises the same question as before, how do we adapt our `Regularization` scheme to the source before we've\n",
        "reconstructed it? Just like in the last tutorial, we'll use a model image of a strongly lensed source from a previous\n",
        "phase of the pipeline that we've begun calling the `hyper-galaxy-image`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#%matplotlib inline\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we'll use the same strong lensing data as the previous tutorial, where:\n",
        "\n",
        " - The lens galaxy's light is omitted.\n",
        " - The lens galaxy's total mass distribution is an `EllipticalIsothermal`.\n",
        " - The source galaxy's `LightProfile` is an `EllipticalSersic`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"mass_sie__source_sersic\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", \"no_lens_light\", dataset_name)\n",
        "\n",
        "imaging = al.Imaging.from_fits(\n",
        "    image_path=path.join(dataset_path, \"image.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=imaging.shape_native,\n",
        "    pixel_scales=imaging.pixel_scales,\n",
        "    sub_size=2,\n",
        "    radius=3.0,\n",
        ")\n",
        "\n",
        "masked_imaging = al.MaskedImaging(\n",
        "    imaging=imaging,\n",
        "    mask=mask,\n",
        "    settings=al.SettingsMaskedImaging(grid_class=al.Grid2D, sub_size=2),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we're going to fit the image using our magnification based grid. To perform the fits, we'll use a convenience \n",
        "function to fit the lens data we simulated above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "def fit_masked_imaging_with_source_galaxy(masked_imaging, source_galaxy):\n",
        "\n",
        "    lens_galaxy = al.Galaxy(\n",
        "        redshift=0.5,\n",
        "        mass=al.mp.EllipticalIsothermal(\n",
        "            centre=(0.0, 0.0),\n",
        "            einstein_radius=1.6,\n",
        "            elliptical_comps=al.convert.elliptical_comps_from(axis_ratio=0.9, phi=45.0),\n",
        "        ),\n",
        "        shear=al.mp.ExternalShear(elliptical_comps=(0.05, 0.05)),\n",
        "    )\n",
        "\n",
        "    tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_galaxy])\n",
        "\n",
        "    return al.FitImaging(masked_imaging=masked_imaging, tracer=tracer)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we'll use the magnification based source to fit this data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "source_magnification = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    pixelization=al.pix.VoronoiMagnification(shape=(30, 30)),\n",
        "    regularization=al.reg.Constant(coefficient=3.3),\n",
        ")\n",
        "\n",
        "fit = fit_masked_imaging_with_source_galaxy(\n",
        "    masked_imaging=masked_imaging, source_galaxy=source_magnification\n",
        ")\n",
        "\n",
        "include_2d = aplt.Include2D(\n",
        "    mask=True, mapper_data_pixelization_grid=True, mapper_source_pixelization_grid=True\n",
        ")\n",
        "\n",
        "fit_imaging_plotter = aplt.FitImagingPlotter(fit=fit, include_2d=include_2d)\n",
        "fit_imaging_plotter.subplot_fit_imaging()\n",
        "fit_imaging_plotter.figures_of_planes(plane_image=True, plane_index=1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Okay, so the inversion`s fit looks just like it did in the previous tutorials. Lets quickly remind ourselves that \n",
        "the effective regularization_coefficient of each source pixel is our input coefficient value of 3.3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inversion_plotter = fit_imaging_plotter.inversion_plotter_of_plane(plane_index=1)\n",
        "inversion_plotter.figures(regularization_weights=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets now look at adaptive `Regularization`.n action, by setting up a hyper-galaxy-image and using the \n",
        "`AdaptiveBrightness` `Regularization` scheme. This introduces additional hyper-galaxy-parameters, that I'll explain next."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "hyper_image = fit.model_image.slim_binned\n",
        "\n",
        "source_adaptive_regularization = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    pixelization=al.pix.VoronoiMagnification(shape=(30, 30)),\n",
        "    regularization=al.reg.AdaptiveBrightness(\n",
        "        inner_coefficient=0.005, outer_coefficient=1.9, signal_scale=3.0\n",
        "    ),\n",
        "    hyper_galaxy_image=hyper_image,\n",
        ")\n",
        "\n",
        "fit = fit_masked_imaging_with_source_galaxy(\n",
        "    masked_imaging=masked_imaging, source_galaxy=source_adaptive_regularization\n",
        ")\n",
        "\n",
        "inversion_plotter = fit_imaging_plotter.inversion_plotter_of_plane(plane_index=1)\n",
        "inversion_plotter.figures(reconstruction=True, regularization_weights=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So, as expected, we now have a variable `Regularization` scheme. The `Regularization`.f the source's brightest regions \n",
        "is much lower than that of its outer regions. As discussed before, this is what we want. Lets quickly check that this \n",
        "does, indeed, increase the Bayesian log evidence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Evidence using constant `Regularization`. \", 4216)\n",
        "print(\"Evidence using adaptive `Regularization`. \", fit.log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Yep! Of course, combining the adaptive `Pixelization` and `Regularization`.ill only further benefit our lens modeling!\n",
        "\n",
        "However, as shown below, we don't fit the source as well as the morphology based `Pixelization` did in the last chapter. \n",
        "This is because although the adaptive `Regularization` scheme improves the fit, the magnification based \n",
        "_Pixelization_ simply *does not*  have sufficient resolution to resolve the source's cuspy central `LightProfile`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_imaging_plotter = aplt.FitImagingPlotter(fit=fit, include_2d=include_2d)\n",
        "fit_imaging_plotter.subplot_fit_imaging()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__How does adaptive `Regularization` work?__\n",
        "\n",
        "For every source-pixel, we have a mapping between that pixel and a set of pixels in the hyper-galaxy-image. Therefore, \n",
        "for every source-pixel, if we sum the values of all hyper-galaxy-image pixels that map to it we get an estimate of \n",
        "how much of the lensed source's signal we expect will be reconstructed. We call this each pixel`s `pixel signal`.\n",
        "\n",
        "If a source-pixel has a higher pixel-signal, we anticipate that it`ll reconstruct more flux and we use this information \n",
        "to regularize it less. Conversely, if the pixel-signal is close to zero, the source pixel will reconstruct near-zero \n",
        "flux and `Regularization`.ill smooth over these pixels by using a high regularization_coefficient.\n",
        "\n",
        "This works as follows:\n",
        "\n",
        " 1) For every source pixel, compute its pixel-signal, the summed flux of all corresponding image-pixels in the \n",
        " hyper-galaxy-image.\n",
        "    \n",
        " 2) Divide every pixel-signal by the number of image-pixels that map directly to that source-pixel. In doing so, all \n",
        " pixel-signals are `relative`. This means that source-pixels which by chance map to more image-pixels than their \n",
        " neighbors will not have a higher pixel-signal, and visa versa. This ensures the specific _Pixelization_\n",
        " does impact the adaptive `Regularization` pattern.\n",
        "    \n",
        " 3) Divide the pixel-signals by the maximum pixel signal so that they range between 0.0 and 1.0.\n",
        "    \n",
        " 4) Raise these values to the power of the hyper-galaxy-parameter *signal_scale*. For a *signal_scale* of 0.0, all \n",
        " pixels will therefore have the same final pixel-scale. As the *signal_scale* increases, a sharper transition of \n",
        " pixel-signal values arises between regions with high and low pixel-signals.\n",
        "    \n",
        " 5) Compute every source pixel`s effective regularization_coefficient as:\n",
        "    \n",
        " (inner_coefficient * pixel_signals + outer_coefficient * (1.0 - pixel_signals)) ** 2.0\n",
        "    \n",
        " This uses two regularization_coefficients, one which is applied to pixels with high pixel-signals and one to \n",
        " pixels with low pixel-signals. Thus, pixels in the inner regions of the source may be given a lower level of \n",
        " `Regularization`.han pixels further away, as desired.\n",
        "\n",
        "Thus, we now adapt our `Regularization` scheme to the source's surface brightness. Where its brighter (and therefore \n",
        "has a steeper flux gradient) we apply a lower level of `Regularization` than further out. Furthermore, in the edges of \n",
        "the source-plane where no source-flux is present we will assume a high regularization_coefficients that smooth over \n",
        "all source-pixels.\n",
        "\n",
        "Try looking at a couple of extra solutions which use with different inner and outer regularization_coefficients or \n",
        "signal scales. I doubt you'll notice a lot change visually, but the log evidence certainly has a lot of room for \n",
        "manoveur with different values.\n",
        "\n",
        "You may find solutions that raise an `InversionException`. These solutions mean that the matrix used during the \n",
        "linear algebra calculation was ill-defined, and could not be inverted. These solutions are removed by **PyAutoLens** \n",
        "during lens modeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "source_adaptive_regularization = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    pixelization=al.pix.VoronoiMagnification(shape=(30, 30)),\n",
        "    regularization=al.reg.AdaptiveBrightness(\n",
        "        inner_coefficient=0.001, outer_coefficient=0.2, signal_scale=2.0\n",
        "    ),\n",
        "    hyper_galaxy_image=hyper_image,\n",
        ")\n",
        "\n",
        "fit = fit_masked_imaging_with_source_galaxy(\n",
        "    masked_imaging=masked_imaging, source_galaxy=source_adaptive_regularization\n",
        ")\n",
        "\n",
        "fit_imaging_plotter = aplt.FitImagingPlotter(fit=fit, include_2d=include_2d)\n",
        "fit_imaging_plotter.subplot_fit_imaging()\n",
        "\n",
        "inversion_plotter = fit_imaging_plotter.inversion_plotter_of_plane(plane_index=1)\n",
        "inversion_plotter.figures(reconstruction=True, regularization_weights=True)\n",
        "\n",
        "print(\"Evidence using adaptive `Regularization`. \", fit.log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To end, lets consider what this adaptive `Regularization` scheme means in the context of maximizing the Bayesian\n",
        "log_evidence. In the previous tutorial, we noted that by using a brightness-based adaptive `Pixelization` we increased \n",
        "the Bayesian log evidence by allowing for new solutions which fit the data user fewer source pixels; the key criteria \n",
        "in making a source reconstruction `more simple` and `less complex`.\n",
        "\n",
        "As you might of guessed, adaptive `Regularization`.gain increases the Bayesian log evidence by making the source \n",
        "reconstruction simpler:\n",
        "\n",
        " 1) Reducing `Regularization` in the source's brightest regions produces a `simpler` solution in that we are not \n",
        " over-smoothing our reconstruction of its brightest regions.\n",
        "    \n",
        " 2) Increasing `Regularization` in the outskirts produces a simpler solution by correlating more source-pixels, \n",
        " effectively reducing the number of pixels used by the reconstruction.\n",
        "\n",
        "Together, brightness based `Pixelization`'s and `Regularization` allow us to find the objectively `simplest` source \n",
        "solution possible and therefore ensure that our Bayesian log evidence`s have a well defined maximum value they are \n",
        "seeking. This was not the case for magnification based `Pixelization`'s and constant `Regularization` schemes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}