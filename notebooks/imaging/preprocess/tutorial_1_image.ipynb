{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preprocess 1: Image\n",
        "===================\n",
        "\n",
        "The image is the image of your strong lens - most likely a co-add of multiple dithered exposures.\n",
        "\n",
        "Throughout all these tutorials, we'll refer to a \"pixel_scale\" when loading data. The pixel-scale describes the\n",
        "pixel-units to arcsecond-units conversion factor of your telescope, which you should look up now if you are unsure\n",
        "of the value. HST `Imaging` typically has a pixel_scale of 0.05\", however this varies depending on the detector and\n",
        "data reduction procedure so DOUBLE CHECK THIS!\n",
        "\n",
        "This tutorial describes preprocessing your dataset`s image to adhere too the units and formats required by PyAutoLens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "#%matplotlib inline\n",
        "from os import path\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setup the path the datasets we'll use to illustrate preprocessing, which is the folder `dataset/imaging/preprocess`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = path.join(\"dataset\", \"imaging\", \"preprocess\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Loading Data From Individual Fits Files__\n",
        "\n",
        "First, lets load an image as an Array2D. This image represents a good data-reduction that conforms to the formatting \n",
        "standards I describe in this tutorial!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "imaging_path = path.join(dataset_path, \"imaging\")\n",
        "\n",
        "image = al.Array2D.from_fits(\n",
        "    file_path=path.join(imaging_path, \"image.fits\"), pixel_scales=0.1\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are numerous reasons why the image below is a good data-set for lens modeling. I strongly recommend \n",
        "you adapt your data reduction pipelines to conform to the formats discussed below - it`ll make your time using \n",
        "PyAutoLens a lot simpler.\n",
        "\n",
        "However, you may not have access to the data-reduction tools that made the data, so we've included in-built functions \n",
        "in PyAutoLens to convert the data to a suitable format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "array_plotter = aplt.Array2DPlotter(array=image)\n",
        "array_plotter.figure()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__1) Converting Data To Electrons Per Second__\n",
        "\n",
        "1) Brightness units - the image`s flux values should be in units of electrons per second (as opposed to electrons, \n",
        "counts, ADU`s etc.). Although PyAutoLens can technically perform an analysis using other units, the default setup \n",
        "assumes electrons per second (e.g. the priors on `LightProfile` intensity and `Regularization` parameters). Thus, images \n",
        "not in electrons per second should be converted!\n",
        "\n",
        "Lets look at an image that is in units of counts - its easy to tell because the peak values are in the 1000`s or 10000`s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "imaging_path = f\"{dataset_path}/imaging_in_counts\"\n",
        "\n",
        "image_in_counts = al.Array2D.from_fits(\n",
        "    file_path=path.join(imaging_path, \"image.fits\"), pixel_scales=0.1\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=image_in_counts)\n",
        "array_plotter.figure()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Converting from counts to electrons per second means we must know the exposure time of our observation, which should be\n",
        "an output of your data reduction pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "exposure_time = 1000.0\n",
        "\n",
        "exposure_time_map = al.Array2D.full(\n",
        "    fill_value=exposure_time,\n",
        "    shape_native=image_in_counts.shape_native,\n",
        "    pixel_scales=image_in_counts.pixel_scales,\n",
        ")\n",
        "\n",
        "image_converted_to_eps = al.preprocess.array_counts_to_eps(\n",
        "    array_counts=image_in_counts, exposure_time_map=exposure_time_map\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=image_converted_to_eps)\n",
        "array_plotter.figure()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the effective exposure-time map is output as part of the data reduction, you can use this to convert the image to \n",
        "electrons per second instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "exposure_time_map = al.Array2D.from_fits(\n",
        "    file_path=f\"{imaging_path}/exposure_time_map.fits\",\n",
        "    pixel_scales=image_converted_to_eps.pixel_scales,\n",
        ")\n",
        "\n",
        "image_converted_to_eps = al.preprocess.array_counts_to_eps(\n",
        "    array_counts=image_in_counts, exposure_time_map=exposure_time_map\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=image_converted_to_eps)\n",
        "array_plotter.figure()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PyAutoLens can also convert data from units of ADUs to electrons per second, which uses both the exposure time and\n",
        "instrumental gain of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "imaging_path = f\"{dataset_path}/imaging_in_adus\"\n",
        "\n",
        "image_in_adus = al.Array2D.from_fits(\n",
        "    file_path=path.join(imaging_path, \"image.fits\"), pixel_scales=0.1\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=image_in_adus)\n",
        "array_plotter.figure()\n",
        "\n",
        "exposure_time_map = al.Array2D.full(\n",
        "    fill_value=1000.0,\n",
        "    shape_native=image_in_counts.shape_native,\n",
        "    pixel_scales=image_in_adus.pixel_scales,\n",
        ")\n",
        "\n",
        "image_converted_to_eps = al.preprocess.array_adus_to_eps(\n",
        "    array_adus=image_in_adus, exposure_time_map=exposure_time_map, gain=4.0\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=image_converted_to_eps)\n",
        "array_plotter.figure()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In `autolens_workspace/notebooks/preprocess/prepare/noise_map.py` we show that a noise-map must also be in units of electrons \n",
        "per second, and that the same functions as above can be used to do this.\n",
        "\n",
        "2)__Resizing Data__\n",
        "\n",
        "The bigger the postage stamp cut-out of the image the more memory it requires to store. Visualization will be less \n",
        "ideal too, as the lens will be a small blob in the centre relative to the large surrounding edges of the image. Why \n",
        "keep the edges surrounding the lens if they are masked out anyway?\n",
        "\n",
        "Lets look at an example of a very large postage stamp - we can barely even see the lens and source galaxies!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "imaging_path = f\"{dataset_path}/imaging_with_large_stamp\"\n",
        "\n",
        "image_large_stamp = al.Array2D.from_fits(\n",
        "    file_path=path.join(imaging_path, \"image.fits\"), pixel_scales=0.1\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=image_large_stamp)\n",
        "array_plotter.figure()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you have a large postage stamp you can trim it using the preprocess module. Trimming is centred on the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_large_stamp_trimmed = al.preprocess.array_with_new_shape(\n",
        "    array=image_large_stamp, new_shape=(130, 130)\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=image_large_stamp_trimmed)\n",
        "array_plotter.figure()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The stamp may also be too small. It must have sufficient padding around the border that our mask includes all \n",
        "pixels with signal. More importantly, the padding must also stretch into the `blurring region`, corresponding to all \n",
        "unmasked image pixels where light blurs into the masks after PSF convolution. Thus, we may need to pad an image to \n",
        "include_2d this region."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "imaging_path = f\"{dataset_path}/imaging_with_small_stamp\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This image is an example of a stamp which is big enough to contain the lens and source galaxies, but when we apply a \n",
        "sensible masks we get an error, because the masks`s blurring region goes into the edge of the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_small_stamp = al.Array2D.from_fits(\n",
        "    file_path=path.join(imaging_path, \"image.fits\"), pixel_scales=0.1\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=image_small_stamp)\n",
        "array_plotter.figure()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we apply a masks to this image we get an error when we try to use it to set up a masked image because its \n",
        "blurring region (defined by the PSF kernel shape) hits the image edge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = al.Mask2D.circular(\n",
        "    shape_native=image_small_stamp.shape_native,\n",
        "    pixel_scales=image_small_stamp.pixel_scales,\n",
        "    radius=2.0,\n",
        ")\n",
        "\n",
        "visuals_2d = aplt.Visuals2D(mask=mask)\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=image_small_stamp, visuals_2d=visuals_2d)\n",
        "array_plotter.figure()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The setup of the Convolver (used to perform PSF blurring in a PyAutoLens analysis) now gives an error because the \n",
        "mask`s edge and therefore blurring region goes over the edge of the edge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# convolver = al.Convolver(mask=mask, kernel=al.Kernel2D.ones(shape_native=(31, 31)))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We overcome this using the same function as before. However, the resized image shape now becomes bigger than the \n",
        "image, by padding zeros at the edges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_small_stamp_padded = al.preprocess.array_with_new_shape(\n",
        "    array=image_small_stamp, new_shape=(130, 130)\n",
        ")\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=image_small_stamp_padded.shape_native,\n",
        "    pixel_scales=image_small_stamp_padded.pixel_scales,\n",
        "    radius=2.0,\n",
        ")\n",
        "\n",
        "visuals_2d = aplt.Visuals2D(mask=mask)\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(\n",
        "    array=image_small_stamp_padded, visuals_2d=visuals_2d\n",
        ")\n",
        "array_plotter.figure()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This no longer gives an error!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "convolver = al.Convolver(\n",
        "    mask=mask,\n",
        "    kernel=al.Kernel2D.ones(shape_native=(31, 31), pixel_scales=mask.pixel_scales),\n",
        ")\n",
        "\n",
        "# 3) ``.entering__\n",
        "\n",
        "########## IVE INCLUDED THE TEXT CAN BE AWARE OF CENTERING, BUT THE BUILT IN FUNCTIONALITY FOR #####\n",
        "########## RECENTERING CURRENTLY DOES NOT WORK :( ###########\n",
        "\n",
        "# Lens Galaxy Centering - The lens galaxy should be in the centre of the image as opposed to a corner. This ensures\n",
        "# the origin of the lens galaxy's light and `MassProfile`'s are near the origin (0.0\", 0.0\") of the grid used to perform\n",
        "# ray-tracing. The defaults priors on light and `MassProfile`'s assume a origin of (0.0\", 0.0\").\n",
        "\n",
        "# Lets look at an off-center image - clearly both the lens galaxy and Einstein ring are offset in the positive y and x d\n",
        "# directions.\n",
        "\n",
        "# imaging_path = f\"{dataset_path}/imaging_offset_centre\"\n",
        "\n",
        "# imaging_offset_centre = al.Imaging.from_fits(image_path=path+`image.fits`, pixel_scales=0.1,\n",
        "#                                   noise_map_path=path+`noise_map.fits`,\n",
        "#                                   psf_path=path+`psf.fits`)\n",
        "# aplt.Imaging.subplot(imaging=imaging_offset_centre)\n",
        "\n",
        "# We can address this by using supplying a new centre for the image, in pixels. We also supply the resized shape, to\n",
        "# instruct the code whether it should trim the image or pad the edges that now arise due to recentering.\n",
        "\n",
        "# imaging_recentred_pixels = al.Imaging.from_fits(image_path=path+`image.fits`, pixel_scales=0.1,\n",
        "#                                             noise_map_path=path+`noise_map.fits`,\n",
        "#                                             psf_path=path+`psf.fits`,\n",
        "#                                             resized_imaging_shape=(100, 100),\n",
        "#                                             resized_imaging_centre_pixels=(0, 0))\n",
        "# #                                            resized_imaging_centre_arc_seconds=(1.0, 1.0))\n",
        "# print(imaging_recentred_pixels.shape)\n",
        "# aplt.Imaging.subplot(imaging=imaging_recentred_pixels)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}