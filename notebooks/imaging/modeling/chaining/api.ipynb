{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Example: Chaining Phases API__\n",
        "\n",
        "In the `beginner` examples all model-fits were performed using one phase, which composed the lens model using one\n",
        "parametrization and performed the model-fit using one non-linear search. In the `chaining` examples we break the\n",
        "model-fitting procedure down into multiple phases, chaining the results of the initial phases to subsequent phases.\n",
        "This allows us to guide the model-fitting procedure as to where it should look in parameter space for the\n",
        "highest log-likelihood models.\n",
        "\n",
        "When chaining phases:\n",
        "\n",
        " - The earlier phases fit simpler model parameterizations than the later phases, providing them with a less complex\n",
        "   non-linear parameter space that can be sampled more efficiently and with a reduced chance of inferring an\n",
        "   incorrect local maxima solution.\n",
        "\n",
        " - The earlier phases may use `NonLinearSearch` techniques that only seek to maximize the log likelihood and do not\n",
        "   precisely quantify the errors on every parameter, whereas the latter phases do. Alternative, they may use a\n",
        "   `NonLinearSearch` which does compute errors, but with settings that make sampling faster or omit accurately\n",
        "   quantifying the errors.\n",
        "\n",
        "This means we can `initialize` a model-fit very quickly and only spend more computational time estimating errors\n",
        "in the final phase when we actually require them.\n",
        "\n",
        " - The earlier phases can use the `SettingsPhaseImaging` object to augment the data or alter the fitting-procedure\n",
        "   in ways that speed up the computational run time. These may impact the quality of the model-fit overall, but they\n",
        "   can be reverted to the more accurate but more computationally expense setting in the final phases.\n",
        "\n",
        "This script gives an overview of the API for phase chaining, a description of how priors are chained and tools for\n",
        "customizing prior chaining. The other scripts in the `model/chaining` folder give examples of when, for lens modeling,\n",
        "it is beneficial to chain priors, often changing the model between the two phases.\n",
        "\n",
        "Prior chaining is crucial for using the PyAutoLens pipelines found in the folder `autolens_workspace/pipelines`. This\n",
        "example provide a conceptual overview of why prior chaining is used and an introduction to the API used to do so.\n",
        "\n",
        "More details on prior chaining can be found in Chapter 2 of the HowToLens lectures, specifically\n",
        "`tutorial_5_chaining_phases.py`.\n",
        "\n",
        "This example scripts show a simple example of prior chaining, where we fit `Imaging` of a strong lens system where:\n",
        "\n",
        " - The lens galaxy's light is omitted (and is not present in the simulated data).\n",
        " - The lens galaxy's total mass distribution is modeled as an `EllipticalIsothermal`.\n",
        " - The source galaxy's light is modeled parametrically as an `EllipticalSersic`.\n",
        "\n",
        "As discussed below, the first phase is set up to provide as fast a model-fit as possible without accurately quantifying\n",
        "the errors on every parameter, whereas the second phase sacrifices this run-speed for accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As per usual, load the `Imaging` data, create the `Mask2D` and plot them. In this strong lensing dataset:\n",
        "\n",
        " - The lens galaxy's light is omitted.\n",
        " - The lens galaxy's total mass distribution is an `EllipticalIsothermal`.\n",
        " - The source galaxy's `LightProfile` is an `EllipticalExponential`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"mass_sie__source_sersic\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", \"no_lens_light\", dataset_name)\n",
        "\n",
        "imaging = al.Imaging.from_fits(\n",
        "    image_path=path.join(dataset_path, \"image.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=imaging.shape_native, pixel_scales=imaging.pixel_scales, radius=3.0\n",
        ")\n",
        "\n",
        "imaging_plotter = aplt.ImagingPlotter(\n",
        "    imaging=imaging, visuals_2d=aplt.Visuals2D(mask=mask)\n",
        ")\n",
        "imaging_plotter.subplot_imaging()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose our lens model using `GalaxyModel` objects, which represent the galaxies we fit to our data. In this \n",
        "example our lens mooel is:\n",
        "\n",
        " - An `EllipticalIsothermal` `MassProfile`.for the lens galaxy's mass (5 parameters).\n",
        " - An `EllipticalSersic` `LightProfile`.for the source galaxy's light (6 parameters).\n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=11."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens = al.GalaxyModel(redshift=0.5, mass=al.mp.EllipticalIsothermal)\n",
        "source = al.GalaxyModel(redshift=1.0, bulge=al.lp.EllipticalSersic)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Settings__\n",
        "\n",
        "You should be familiar with the `SettingsPhaseImaging` object from other example scripts, if not checkout the beginner\n",
        "examples and `autolens_workspace/notebooks/imaging/modeling/customize/settings.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "settings = al.SettingsPhaseImaging()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "You should be familiar with non-linear searches from other example scripts if not checkout the bginner examples\n",
        "and `autolens_workspace/notebooks/imaging/modeling/customize/non_linear_searches.py`.\n",
        "\n",
        "In phase 1, we again use `Dynesty` however we set a new input parameter the `evidence_tolerance`. This is essentially\n",
        "the stopping criteria of `Dynesty`, where high values means that it stops sampling earlier, at the expense of less\n",
        "robust parameter estimates and larger inferred parameter errors. Given we want phase 1 to be fast, we do not mind\n",
        "either of these things happening. \n",
        "    \n",
        "You should also note the `PriorPasser` object input into the search. We will describe this in a moment, but you\n",
        "should run the script and model-fit first.\n",
        "\n",
        "The `name` and `path_prefix` below specify the path where results are stored in the output folder:  \n",
        "\n",
        " `/autolens_workspace/output/examples/chaining/api/mass_sie__source_sersic/phase[1]`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.DynestyStatic(\n",
        "    path_prefix=path.join(\"imaging\", \"chaining\", \"api\"),\n",
        "    name=\"phase[1]\",\n",
        "    n_live_points=50,\n",
        "    evidence_tolerance=20.0,\n",
        "    prior_passer=af.PriorPasser(sigma=5.0, use_widths=True, use_errors=False),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Phase__\n",
        "\n",
        "We can now combine the model, settings and search to create and run a phase, fitting our data with the lens model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "phase1 = al.PhaseImaging(\n",
        "    settings=settings,\n",
        "    galaxies=af.CollectionPriorModel(lens=lens, source=source),\n",
        "    search=search,\n",
        ")\n",
        "\n",
        "phase1_result = phase1.run(dataset=imaging, mask=mask)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before reading on to phase 2, you may wish to inspect the results of the phase 1 model-fit to ensure the fast\n",
        "non-linear search has provided a reasonably accurate lens model.\n",
        "\n",
        "__Model Chaining__\n",
        "\n",
        "We use the results of phase 1 to create the `GalaxyModel` components that we fit in phase 2.\n",
        "\n",
        "The term `model` below tells PyAutoLens to pass the lens and source models as model-components that are to be fitted\n",
        "for by the non-linear search. In other chaining examples, we'll see other ways to pass prior results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens = phase1_result.model.galaxies.lens\n",
        "source = phase1_result.model.galaxies.source"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "In phase 2, we use the nested sampling algorithm `Dynesty`, which we used in the beginner examples. `Dynesty` fully\n",
        "maps out the posterior in parameter space, taking longer to run but providing errors on every model parameter. \n",
        "\n",
        "We can use fewer live points than we did in the beginner tutorials, given that prior chaining now informs `Dynesty` \n",
        "where to search parameter space.\n",
        "\n",
        "The `name` and `path_prefix` below specify the path where results are stored in the output folder:  \n",
        "\n",
        " `/autolens_workspace/output/examples/chaining/api/mass_sie__source_sersic/phase[2]`.\n",
        "\n",
        "Note how the `lens` and `source` passed to this phase were set up above using the results of phase 1!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.DynestyStatic(\n",
        "    path_prefix=path.join(\"imaging\", \"chaining\", \"api\"),\n",
        "    name=\"phase[2]\",\n",
        "    n_live_points=30,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Phase__\n",
        "\n",
        "We can now combine the model, settings and search to create and run a phase, fitting our data with the lens model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "phase2 = al.PhaseImaging(\n",
        "    settings=settings,\n",
        "    galaxies=af.CollectionPriorModel(lens=lens, source=source),\n",
        "    search=search,\n",
        ")\n",
        "\n",
        "phase2.run(dataset=imaging, mask=mask)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Prior Passing__\n",
        "\n",
        "Once phase 2 is running, you should checkout its `model.info` file. The parameters do not use the default priors we saw\n",
        "in the beginner turorials or phase 1 (which are typically broad UniformPriors). Instead, it uses GaussianPrior`s where:\n",
        "\n",
        " - The mean values are the median PDF results of every parameter in phase 1.\n",
        " - Many sigma values are the errors computed at 3.0 sigma confidence of every parameter in phase 1.\n",
        " - Other sigma values are higher than the errors computed at 3.0 sigma confidence. These instead use the value \n",
        "      specified in the `width_modifier` field of the `Profile`'s entry in the `json_config` files.\n",
        "\n",
        "The `width_modifier` is used instead of the errors computed from phase 1 when the errors values estimated are smaller \n",
        "than the width modifier value. This ensure that the sigma values used for priors in phase 2 do not assume extremely \n",
        "small values (e.g. a value of < 0.01 for an einstein_radius) if the error estimates in phase 1 are very small, which\n",
        "may occur when using a fast `NonLinearSearch` or fitting an overly simplified model.\n",
        "    \n",
        "Thus, phase 2 used the results of phase 1 to inform it where to search non-linear parameter space! \n",
        "\n",
        "The PriorPasser customizes how priors are passed from phase 1 as follows:\n",
        "\n",
        " - sigma: The sigma value that the errors passed to use as the sigma values in phase 1 are estimated at.\n",
        " - use_widths: If False, the \"width_modifier\" values in the json_prior configs are not used to override a passed\n",
        "                  error value.\n",
        " - use_errors: If False, errors are not passed from phase 1 to set up the priors and only the \"width\" modifier\n",
        "                  entries in the configs are used.  \n",
        "\n",
        "For the interested read a complete description of prior passing is given in chapter 2, tutorial 5 of HowToLens. Below\n",
        "is an extract of the full prior passing description.\n",
        "\n",
        "__HowToLens Prior Passing__\n",
        "\n",
        "Lets say I chain two parameters as follows:\n",
        "\n",
        "    mass.einstein_radius = phase1_result.model.galaxies.lens.mass.einstein_radius\n",
        "\n",
        "By invoking the `model` attribute, the prioris passed following 3 rules:\n",
        "\n",
        "    1) The new parameter, in this case the einstein radius, uses a GaussianPrior. A GaussianPrior is ideal, as the 1D \n",
        "       pdf results we compute at the end of a phase are easily summarized as a Gaussian.\n",
        "\n",
        "    2) The mean of the GaussianPrior is the median PDF value of the parameter estimated in phase 1.\n",
        "\n",
        "      This ensures that the initial sampling of the new phase`s non-linear starts by searching the region of non-linear \n",
        "      parameter space that correspond to highest log likelihood solutions in the previous phase. Thus, we`re setting \n",
        "      our priors to look in the `correct` regions of parameter space.\n",
        "\n",
        "    3) The sigma of the Gaussian will use the maximum of two values: \n",
        "\n",
        "            (i) the 1D error of the parameter computed at an input sigma value (default sigma=3.0).\n",
        "            (ii) The value specified for the profile in the `config/priors/*.json` config file`s `width_modifer` \n",
        "                 field (check these files out now).\n",
        "\n",
        "       The idea here is simple. We want a value of sigma that gives a GaussianPrior wide enough to search a broad \n",
        "       region of parameter space, so that the lens model can change if a better solution is nearby. However, we want it \n",
        "       to be narrow enough that we don't search too much of parameter space, as this will be slow or risk leading us \n",
        "       into an incorrect solution! A natural choice is the errors of the parameter from the previous phase.\n",
        "\n",
        "       Unfortunately, this doesn`t always work. Lens modeling is prone to an effect called `over-fitting` where we \n",
        "       underestimate the errors on our lens model parameters. This is especially true when we take the shortcuts in \n",
        "       early phases - fast `NonLinearSearch` settings, simplified lens models, etc.\n",
        "\n",
        "       Therefore, the `width_modifier` in the json config files are our fallback. If the error on a parameter is \n",
        "       suspiciously small, we instead use the value specified in the widths file. These values are chosen based on \n",
        "       our experience as being a good balance broadly sampling parameter space but not being so narrow important \n",
        "       solutions are missed. \n",
        "\n",
        "There are two ways a value is specified using the priors/width file:\n",
        "\n",
        "    1) Absolute: In this case, the error assumed on the parameter is the value given in the config file. \n",
        "       For example, if for the width on centre_0 of a `LightProfile`, the width modifier reads \"Absolute\" with a value \n",
        "       0.05. This means if the error on the parameter centre_0 was less than 0.05 in the previous phase, the sigma of \n",
        "       its GaussianPrior in this phase will be 0.05.\n",
        "\n",
        "    2) Relative: In this case, the error assumed on the parameter is the % of the value of the \n",
        "       estimate value given in the config file. For example, if the intensity estimated in the previous phase was 2.0, \n",
        "       and the relative error in the config file reads \"Relative\" with a value 0.5, then the sigma of the GaussianPrior \n",
        "       will be 50% of this value, i.e. sigma = 0.5 * 2.0 = 1.0.\n",
        "\n",
        "We use absolute and relative values for different parameters, depending on their properties. For example, using the \n",
        "relative value of a parameter like the `Profile` centre makes no sense. If our lens galaxy is centred at (0.0, 0.0), \n",
        "the relative error will always be tiny and thus poorly defined. Therefore, the default configs in PyAutoLens use \n",
        "absolute errors on the centre.\n",
        "\n",
        "However, there are parameters where using an absolute value does not make sense. Intensity is a good example of this. \n",
        "The intensity of an image depends on its unit_label, S/N, galaxy brightness, etc. There is no single absolute value \n",
        "that one can use to generically chain the intensity of any two proflies. Thus, it makes more sense to chain them using \n",
        "the relative value from a previous phase.\n",
        "\n",
        "We can customize how priors are passed from the results of a phase and `NonLinearSearch` by inputting to the search \n",
        "a PriorPasser object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.DynestyStatic(\n",
        "    prior_passer=af.PriorPasser(sigma=2.0, use_widths=False, use_errors=True)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The PriorPasser allows us to customize at what sigma the error values the model results are computed at to compute\n",
        "the passed sigma values and customizes whether the widths in the config file, these computed errors, or both, \n",
        "are used to set the sigma values of the passed priors.\n",
        "\n",
        "The default values of the PriorPasser are found in the config file of every non-linear search, in the [prior_passer]\n",
        "section. All non-linear searches by default use a sigma value of 3.0, use_width=True and use_errors=True. We anticipate\n",
        "you should not need to change these values to get lens modeling to work proficiently!\n",
        "\n",
        "__EXAMPLE__\n",
        "\n",
        "Lets go through an example using a real parameter. Lets say in phase 1 we fit the lens galaxy's light with an \n",
        "elliptical Sersic profile, and we estimate that its sersic index is equal to 4.0 +- 2.0 where the error value of 2.0 \n",
        "was computed at 3.0 sigma confidence. To pass this as a prior to phase 2, we would write:\n",
        "\n",
        "    lens.bulge.sersic_index = phase1.result.model.lens.bulge.sersic_index\n",
        "\n",
        "The prior on the lens galaxy's sersic `LightProfile` in phase 2 would thus be a GaussianPrior, with mean=4.0 and \n",
        "sigma=2.0. If we had used a sigma value of 1.0 to compute the error, which reduced the estimate from 4.0 +- 2.0 to \n",
        "4.0 +- 1.0, the sigma of the Gaussian prior would instead be 1.0. \n",
        "\n",
        "If the error on the Sersic index in phase 1 had been really small, lets say, 0.01, we would instead use the value of the \n",
        "Sersic index width in the priors config file to set sigma instead. In this case, the prior config file specifies \n",
        "that we use an \"Absolute\" value of 0.8 to chain this prior. Thus, the GaussianPrior in phase 2 would have a mean=4.0 and \n",
        "sigma=0.8.\n",
        "\n",
        "If the prior config file had specified that we use an relative value of 0.8, the GaussianPrior in phase 2 would have a \n",
        "mean=4.0 and sigma=3.2.\n",
        "\n",
        "And with that, we`re done. Chaining priors is a bit of an art form, but one that tends to work really well. Its true to \n",
        "say that things can go wrong - maybe we `trim` out the solution we`re looking for, or underestimate our errors a bit \n",
        "due to making our priors too narrow. However, in general, things are okay, and the example pipelines in \n",
        "`autolens_workspace/pipelines` have been thoroughly tested to ensure prior chaining works effectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}